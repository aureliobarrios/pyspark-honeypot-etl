{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%help",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.5 \n",
					"output_type": "stream"
				},
				{
					"output_type": "display_data",
					"data": {
						"text/markdown": "\n# Available Magic Commands\n\n## Sessions Magic\n\n----\n    %help                             Return a list of descriptions and input types for all magic commands. \n    %profile            String        Specify a profile in your aws configuration to use as the credentials provider.\n    %region             String        Specify the AWS region in which to initialize a session. \n                                      Default from ~/.aws/config on Linux or macOS, \n                                      or C:\\Users\\ USERNAME \\.aws\\config\" on Windows.\n    %idle_timeout       Int           The number of minutes of inactivity after which a session will timeout. \n                                      Default: 2880 minutes (48 hours).\n    %timeout            Int           The number of minutes after which a session will timeout. \n                                      Default: 2880 minutes (48 hours).\n    %session_id_prefix  String        Define a String that will precede all session IDs in the format \n                                      [session_id_prefix]-[session_id]. If a session ID is not provided,\n                                      a random UUID will be generated.\n    %status                           Returns the status of the current Glue session including its duration, \n                                      configuration and executing user / role.\n    %session_id                       Returns the session ID for the running session.\n    %list_sessions                    Lists all currently running sessions by ID.\n    %stop_session                     Stops the current session.\n    %glue_version       String        The version of Glue to be used by this session. \n                                      Currently, the only valid options are 2.0, 3.0 and 4.0. \n                                      Default: 2.0.\n    %reconnect          String        Specify a live session ID to switch/reconnect to the sessions.\n----\n\n## Selecting Session Types\n\n----\n    %streaming          String        Sets the session type to Glue Streaming.\n    %etl                String        Sets the session type to Glue ETL.\n    %glue_ray           String        Sets the session type to Glue Ray.\n    %session_type       String        Specify a session_type to be used. Supported values: streaming, etl and glue_ray. \n----\n\n## Glue Config Magic \n*(common across all session types)*\n\n----\n\n    %%configure         Dictionary    A json-formatted dictionary consisting of all configuration parameters for \n                                      a session. Each parameter can be specified here or through individual magics.\n    %iam_role           String        Specify an IAM role ARN to execute your session with.\n                                      Default from ~/.aws/config on Linux or macOS, \n                                      or C:\\Users\\%USERNAME%\\.aws\\config` on Windows.\n    %number_of_workers  int           The number of workers of a defined worker_type that are allocated \n                                      when a session runs.\n                                      Default: 5.\n    %additional_python_modules  List  Comma separated list of additional Python modules to include in your cluster \n                                      (can be from Pypi or S3).\n    %%tags        Dictionary          Specify a json-formatted dictionary consisting of tags to use in the session.\n    \n    %%assume_role Dictionary, String  Specify a json-formatted dictionary or an IAM role ARN string to create a session \n                                      for cross account access.\n                                      E.g. {valid arn}\n                                      %%assume_role \n                                      'arn:aws:iam::XXXXXXXXXXXX:role/AWSGlueServiceRole' \n                                      E.g. {credentials}\n                                      %%assume_role\n                                      {\n                                            \"aws_access_key_id\" : \"XXXXXXXXXXXX\",\n                                            \"aws_secret_access_key\" : \"XXXXXXXXXXXX\",\n                                            \"aws_session_token\" : \"XXXXXXXXXXXX\"\n                                       }\n----\n\n                                      \n## Magic for Spark Sessions (ETL & Streaming)\n\n----\n    %worker_type        String        Set the type of instances the session will use as workers. \n    %connections        List          Specify a comma separated list of connections to use in the session.\n    %extra_py_files     List          Comma separated list of additional Python files From S3.\n    %extra_jars         List          Comma separated list of additional Jars to include in the cluster.\n    %spark_conf         String        Specify custom spark configurations for your session. \n                                      E.g. %spark_conf spark.serializer=org.apache.spark.serializer.KryoSerializer\n----\n                                      \n## Magic for Ray Session\n\n----\n    %min_workers        Int           The minimum number of workers that are allocated to a Ray session. \n                                      Default: 1.\n    %object_memory_head Int           The percentage of free memory on the instance head node after a warm start. \n                                      Minimum: 0. Maximum: 100.\n    %object_memory_worker Int         The percentage of free memory on the instance worker nodes after a warm start. \n                                      Minimum: 0. Maximum: 100.\n----\n\n## Action Magic\n\n----\n\n    %%sql               String        Run SQL code. All lines after the initial %%sql magic will be passed\n                                      as part of the SQL code.  \n    %matplot      Matplotlib figure   Visualize your data using the matplotlib library.\n                                      E.g. \n                                      import matplotlib.pyplot as plt\n                                      # Set X-axis and Y-axis values\n                                      x = [5, 2, 8, 4, 9]\n                                      y = [10, 4, 8, 5, 2]\n                                      # Create a bar chart \n                                      plt.bar(x, y) \n                                      # Show the plot\n                                      %matplot plt    \n    %plotly            Plotly figure  Visualize your data using the plotly library.\n                                      E.g.\n                                      import plotly.express as px\n                                      #Create a graphical figure\n                                      fig = px.line(x=[\"a\",\"b\",\"c\"], y=[1,3,2], title=\"sample figure\")\n                                      #Show the figure\n                                      %plotly fig\n\n  \n                \n----\n\n"
					},
					"metadata": {}
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 4.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Current idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 5\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 5\nIdle Timeout: 2880\nSession ID: edb5f650-cd81-4883-b4fc-d72d58788f7e\nApplying the following default arguments:\n--glue_kernel_version 1.0.5\n--enable-glue-datacatalog true\nWaiting for session edb5f650-cd81-4883-b4fc-d72d58788f7e to get into ready status...\nSession edb5f650-cd81-4883-b4fc-d72d58788f7e has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Data Transformations",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "s3_path = \"s3://western-shield/batch/\"\n\ndata_frame = glueContext.create_dynamic_frame.from_options(\n    's3',\n    {'paths': [s3_path]},\n    'csv',\n    {'withHeader': True}\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "data_frame.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "{\"@timestamp\": \"May 9, 2024 @ 12:00:00.000\", \"type\": \"P0f\", \"dest_port\": \"28015\", \"geoip.country_code3\": \"US\", \"geoip.city_name\": \"-\", \"geoip.country_name\": \"United States\", \"geoip.ip\": \"199.45.155.25\", \"geoip.latitude\": \"37.75\", \"geoip.longitude\": \"-97.812\"}\n{\"@timestamp\": \"May 9, 2024 @ 12:00:00.000\", \"type\": \"P0f\", \"dest_port\": \"28015\", \"geoip.country_code3\": \"US\", \"geoip.city_name\": \"-\", \"geoip.country_name\": \"United States\", \"geoip.ip\": \"199.45.155.25\", \"geoip.latitude\": \"37.75\", \"geoip.longitude\": \"-97.812\"}\n{\"@timestamp\": \"May 9, 2024 @ 12:00:00.000\", \"type\": \"P0f\", \"dest_port\": \"28015\", \"geoip.country_code3\": \"US\", \"geoip.city_name\": \"-\", \"geoip.country_name\": \"United States\", \"geoip.ip\": \"199.45.155.25\", \"geoip.latitude\": \"37.75\", \"geoip.longitude\": \"-97.812\"}\n{\"@timestamp\": \"May 9, 2024 @ 12:00:00.000\", \"type\": \"P0f\", \"dest_port\": \"28015\", \"geoip.country_code3\": \"US\", \"geoip.city_name\": \"-\", \"geoip.country_name\": \"United States\", \"geoip.ip\": \"199.45.155.25\", \"geoip.latitude\": \"37.75\", \"geoip.longitude\": \"-97.812\"}\n{\"@timestamp\": \"May 9, 2024 @ 12:00:00.000\", \"type\": \"P0f\", \"dest_port\": \"28015\", \"geoip.country_code3\": \"US\", \"geoip.city_name\": \"-\", \"geoip.country_name\": \"United States\", \"geoip.ip\": \"199.45.155.25\", \"geoip.latitude\": \"37.75\", \"geoip.longitude\": \"-97.812\"}\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "data_frame.printSchema()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n|-- @timestamp: string\n|-- type: string\n|-- geoip.country_code2: string\n|-- dest_port: string\n|-- geoip.city_name: string\n|-- geoip.country_name: string\n|-- geoip.ip: string\n|-- geoip.latitude: string\n|-- geoip.longitude: string\n|-- geoip.country_code3: string\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#convert from dynamic frame to pyspark dataframe\ndata_frame = data_frame.toDF()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "data_frame.printSchema()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n |-- @timestamp: string (nullable = true)\n |-- type: string (nullable = true)\n |-- geoip.country_code2: string (nullable = true)\n |-- dest_port: string (nullable = true)\n |-- geoip.city_name: string (nullable = true)\n |-- geoip.country_name: string (nullable = true)\n |-- geoip.ip: string (nullable = true)\n |-- geoip.latitude: string (nullable = true)\n |-- geoip.longitude: string (nullable = true)\n |-- geoip.country_code3: string (nullable = true)\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#get rows where geoip.country_name is not null\ndata_frame.where(\"'geoip.country_name' is NOT NULL\").show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+----+-------------------+---------+---------------+------------------+-------------+--------------+---------------+-------------------+\n|          @timestamp|type|geoip.country_code2|dest_port|geoip.city_name|geoip.country_name|     geoip.ip|geoip.latitude|geoip.longitude|geoip.country_code3|\n+--------------------+----+-------------------+---------+---------------+------------------+-------------+--------------+---------------+-------------------+\n|May 9, 2024 @ 12:...| P0f|               null|    28015|              -|     United States|199.45.155.25|         37.75|        -97.812|                 US|\n|May 9, 2024 @ 12:...| P0f|               null|    28015|              -|     United States|199.45.155.25|         37.75|        -97.812|                 US|\n|May 9, 2024 @ 12:...| P0f|               null|    28015|              -|     United States|199.45.155.25|         37.75|        -97.812|                 US|\n|May 9, 2024 @ 12:...| P0f|               null|    28015|              -|     United States|199.45.155.25|         37.75|        -97.812|                 US|\n|May 9, 2024 @ 12:...| P0f|               null|    28015|              -|     United States|199.45.155.25|         37.75|        -97.812|                 US|\n+--------------------+----+-------------------+---------+---------------+------------------+-------------+--------------+---------------+-------------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql.utils import AnalysisException\n\ntry:\n    data_frame.select(\"geoip.city_name\").show(5)\nexcept AnalysisException:\n    print(\"Having trouble reading columns with . in them!!\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "Having trouble reading columns with . in them!!\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "Having issue selecting columns with a . in their name therefore we are going to rename the columns so that we can access them. ",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "#rename cols\nold_cols = data_frame.schema.names\nnew_cols = []\nfor col in old_cols:\n    new_cols.append(col.replace(\"geoip.\", \"\"))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#rename columns\nfrom functools import reduce\n\ndata_frame = reduce(lambda data_frame, idx: data_frame.withColumnRenamed(old_cols[idx], new_cols[idx]), range(len(old_cols)), data_frame)\ndata_frame.printSchema()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n |-- @timestamp: string (nullable = true)\n |-- type: string (nullable = true)\n |-- country_code2: string (nullable = true)\n |-- dest_port: string (nullable = true)\n |-- city_name: string (nullable = true)\n |-- country_name: string (nullable = true)\n |-- ip: string (nullable = true)\n |-- latitude: string (nullable = true)\n |-- longitude: string (nullable = true)\n |-- country_code3: string (nullable = true)\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#now we can select columns\ndata_frame.select(\"country_code3\").show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 11,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-------------+\n|country_code3|\n+-------------+\n|           US|\n|           US|\n|           US|\n|           US|\n|           US|\n+-------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "data_frame.where(\"'country_name' is NOT NULL\").select([\"country_name\", \"country_code2\", \"country_code3\"]).show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 12,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------+-------------+-------------+\n|  country_name|country_code2|country_code3|\n+--------------+-------------+-------------+\n| United States|         null|           US|\n| United States|         null|           US|\n| United States|         null|           US|\n| United States|         null|           US|\n| United States|         null|           US|\n| United States|         null|           US|\n| United States|         null|           US|\n|             -|         null|            -|\n|             -|         null|            -|\n|             -|         null|            -|\n|             -|         null|            -|\n|             -|         null|            -|\n|United Kingdom|         null|           GB|\n|             -|         null|            -|\n|             -|         null|            -|\n|             -|         null|            -|\n|United Kingdom|         null|           GB|\n|United Kingdom|         null|           GB|\n|             -|         null|            -|\n|             -|         null|            -|\n+--------------+-------------+-------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql.functions import col",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 13,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#select rows where country_name is null\ndata_frame.where(col('country_name').isNull()).show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 14,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----------+----+-------------+---------+---------+------------+---+--------+---------+-------------+\n|@timestamp|type|country_code2|dest_port|city_name|country_name| ip|latitude|longitude|country_code3|\n+----------+----+-------------+---------+---------+------------+---+--------+---------+-------------+\n+----------+----+-------------+---------+---------+------------+---+--------+---------+-------------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "As we can see above when we select rows where country_name is null we get no rows when we know for a fact that there are rows that are empty. In order to do this we must convert rows that are empty from '-' to null.",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "#replace for empty strings\nfrom pyspark.sql.functions import when, lit\n\ndef replace(column, value):\n    return when(column != value, column).otherwise(lit(None))\n\n#replace dash - with null\ndata_frame = data_frame.withColumn(\"country_name\", replace(col(\"country_name\"), \"-\"))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 15,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#now we have null values in our dash strings\ndata_frame.where(col('country_name').isNull()).show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 16,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+--------+-------------+---------+---------+------------+---+--------+---------+-------------+\n|          @timestamp|    type|country_code2|dest_port|city_name|country_name| ip|latitude|longitude|country_code3|\n+--------------------+--------+-------------+---------+---------+------------+---+--------+---------+-------------+\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      547|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|    48946|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|        -|        null|  -|       -|        -|            -|\n+--------------------+--------+-------------+---------+---------+------------+---+--------+---------+-------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "data_frame.groupBy('city_name').count().orderBy(col('count').desc()).show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 17,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-----------------+-------+\n|        city_name|  count|\n+-----------------+-------+\n|                -|3307743|\n|           London| 512968|\n| North Charleston| 472719|\n|     Cedar Knolls| 143898|\n|        Amsterdam| 104848|\n|         Hangzhou|  99665|\n|           Moroni|  97943|\n|            Paris|  83301|\n|          Fremont|  79028|\n|            Cairo|  73472|\n|           Grozny|  64791|\n|      La Libertad|  57400|\n| Ho Chi Minh City|  56652|\n|         Shanghai|  54883|\n|         New York|  50380|\n|         Shenzhen|  50205|\n|           Lahore|  47379|\n|    San Francisco|  43513|\n|     North Bergen|  37462|\n|Frankfurt am Main|  37340|\n+-----------------+-------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "We can see above that the column 'city_name' is another column where there is a large amount of values with '-' in them. These should be null values.",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "#getting all values that have - in them\nnull_cols = []\nfor col_name in data_frame.schema.names:\n    temp_df = data_frame.groupBy(col_name).count()\n    temp_list = temp_df.select(col_name).rdd.flatMap(lambda x: x).collect()\n    if '-' in temp_list:\n        null_cols.append(col_name)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "null_cols",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 19,
			"outputs": [
				{
					"name": "stdout",
					"text": "['country_code2', 'dest_port', 'city_name', 'ip', 'latitude', 'longitude', 'country_code3']\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#for each of those columns we are going to fill with null values\nfor col_name in null_cols:\n    data_frame = data_frame.withColumn(col_name, replace(col(col_name), \"-\"))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 20,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#check to see if we have dashes\ndata_frame.where(col('latitude') == '-').show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 21,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----------+----+-------------+---------+---------+------------+---+--------+---------+-------------+\n|@timestamp|type|country_code2|dest_port|city_name|country_name| ip|latitude|longitude|country_code3|\n+----------+----+-------------+---------+---------+------------+---+--------+---------+-------------+\n+----------+----+-------------+---------+---------+------------+---+--------+---------+-------------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#now we have null values in our dash strings\ndata_frame.where(col('latitude').isNull()).show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 22,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+--------+-------------+---------+---------+------------+----+--------+---------+-------------+\n|          @timestamp|    type|country_code2|dest_port|city_name|country_name|  ip|latitude|longitude|country_code3|\n+--------------------+--------+-------------+---------+---------+------------+----+--------+---------+-------------+\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      547|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|    48946|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n|May 9, 2024 @ 11:...|Suricata|         null|      443|     null|        null|null|    null|     null|         null|\n+--------------------+--------+-------------+---------+---------+------------+----+--------+---------+-------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "null_count_dic = { col_name: data_frame.where(col(col_name).isNull()).count() for col_name in data_frame.schema.names }",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 23,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "null_count_dic",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 24,
			"outputs": [
				{
					"name": "stdout",
					"text": "{'@timestamp': 0, 'type': 0, 'country_code2': 1831198, 'dest_port': 78421, 'city_name': 3307743, 'country_name': 1402550, 'ip': 1402111, 'latitude': 1402550, 'longitude': 1402550, 'country_code3': 6054922}\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#lets take a look at columns that have zero nulls to make sure there arent any nulls for sure\ndata_frame.groupBy('@timestamp').count().orderBy(col('count').desc()).show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 25,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+-----+\n|          @timestamp|count|\n+--------------------+-----+\n|May 18, 2024 @ 14...| 1571|\n|May 17, 2024 @ 17...| 1376|\n|May 17, 2024 @ 17...|  937|\n|May 18, 2024 @ 14...|  748|\n|May 9, 2024 @ 22:...|  730|\n|May 9, 2024 @ 22:...|  452|\n|May 14, 2024 @ 03...|  390|\n|May 9, 2024 @ 22:...|  338|\n|May 13, 2024 @ 13...|  206|\n|May 19, 2024 @ 03...|  192|\n|May 19, 2024 @ 03...|  172|\n|May 19, 2024 @ 03...|  164|\n|May 17, 2024 @ 16...|  162|\n|May 9, 2024 @ 14:...|  161|\n|May 9, 2024 @ 14:...|  157|\n|May 17, 2024 @ 16...|  153|\n|May 19, 2024 @ 18...|  152|\n|May 18, 2024 @ 03...|  148|\n|May 18, 2024 @ 03...|  146|\n|May 18, 2024 @ 03...|  142|\n+--------------------+-----+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "data_frame.groupBy('type').count().orderBy(col('count').desc()).show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 26,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------+-------+\n|          type|  count|\n+--------------+-------+\n|           P0f|3113646|\n|      Suricata|2878781|\n|     Honeytrap| 143528|\n|          Fatt| 136085|\n|       Dionaea|  83896|\n|        Cowrie|  57804|\n|         NGINX|  28726|\n|     Heralding|  23554|\n|      Ciscoasa|   4582|\n|        Tanner|   4182|\n|CitrixHoneypot|   2939|\n|      Mailoney|   1800|\n| Redishoneypot|   1653|\n|        ConPot|    957|\n|      Adbhoney|    700|\n|    Sentrypeer|    338|\n|    ElasticPot|    206|\n|      Dicompot|    137|\n|      Ipphoney|     49|\n|       ssh-rsa|      7|\n+--------------+-------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "After manually checking the columns with 0 null values it does seem to fit that these values are not null. The type column has a large amount of 'P0f' values, I would need to get a better understanding of this value to understand if this could be classified as a null value or not.\n\nThe next task in our data transformations would be to tackle the country_name, country_code2 and country_code3 columns since these seem to be columns that should gather the same information. The country_name column is the column with least null values so maybe we can insert some of that information into the country_code2 and country_code2 columns.",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "data_frame.where((col('country_name').isNotNull()) & (col('country_code2').isNull())).count()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 27,
			"outputs": [
				{
					"name": "stdout",
					"text": "428648\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "data_frame.where((col('country_name').isNotNull()) & (col('country_code2').isNull())).show(10)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 28,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+---------+-------------+---------+---------+--------------+-------------+--------+---------+-------------+\n|          @timestamp|     type|country_code2|dest_port|city_name|  country_name|           ip|latitude|longitude|country_code3|\n+--------------------+---------+-------------+---------+---------+--------------+-------------+--------+---------+-------------+\n|May 9, 2024 @ 12:...|      P0f|         null|    28015|     null| United States|199.45.155.25|   37.75|  -97.812|           US|\n|May 9, 2024 @ 12:...|      P0f|         null|    28015|     null| United States|199.45.155.25|   37.75|  -97.812|           US|\n|May 9, 2024 @ 12:...|      P0f|         null|    28015|     null| United States|199.45.155.25|   37.75|  -97.812|           US|\n|May 9, 2024 @ 12:...|      P0f|         null|    28015|     null| United States|199.45.155.25|   37.75|  -97.812|           US|\n|May 9, 2024 @ 12:...|      P0f|         null|    28015|     null| United States|199.45.155.25|   37.75|  -97.812|           US|\n|May 9, 2024 @ 12:...|      P0f|         null|    28015|     null| United States|199.45.155.25|   37.75|  -97.812|           US|\n|May 9, 2024 @ 12:...|Honeytrap|         null|    28015|     null| United States|199.45.155.25|   37.75|  -97.812|           US|\n|May 9, 2024 @ 11:...| Suricata|         null|    10250|   London|United Kingdom|   3.9.144.57|    51.5|   -0.093|           GB|\n|May 9, 2024 @ 11:...| Suricata|         null|    10250|   London|United Kingdom|   3.9.144.57|    51.5|   -0.093|           GB|\n|May 9, 2024 @ 11:...| Suricata|         null|    10250|   London|United Kingdom|   3.9.144.57|    51.5|   -0.093|           GB|\n+--------------------+---------+-------------+---------+---------+--------------+-------------+--------+---------+-------------+\nonly showing top 10 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "data_frame.where((col('country_name').isNotNull()) & (col('country_code3').isNull())).count()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 29,
			"outputs": [
				{
					"name": "stdout",
					"text": "4652372\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "data_frame.where((col('country_name').isNotNull()) & (col('country_code3').isNull())).show(10)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 30,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+---------+-------------+---------+----------------+--------------+---------------+--------+---------+-------------+\n|          @timestamp|     type|country_code2|dest_port|       city_name|  country_name|             ip|latitude|longitude|country_code3|\n+--------------------+---------+-------------+---------+----------------+--------------+---------------+--------+---------+-------------+\n|May 14, 2024 @ 05...| Suricata|           US|    20358|North Charleston| United States|162.216.150.213|  32.875|      -80|         null|\n|May 14, 2024 @ 05...| Suricata|           US|    20358|North Charleston| United States|162.216.150.213|  32.875|      -80|         null|\n|May 14, 2024 @ 05...|      P0f|           GB|    49691|            null|United Kingdom| 87.236.176.161|    51.5|   -0.122|         null|\n|May 14, 2024 @ 05...|      P0f|           GB|    49691|            null|United Kingdom| 87.236.176.161|    51.5|   -0.122|         null|\n|May 14, 2024 @ 05...|Honeytrap|           GB|    49691|            null|United Kingdom| 87.236.176.161|    51.5|   -0.122|         null|\n|May 14, 2024 @ 05...|      P0f|           GB|    49691|            null|United Kingdom| 87.236.176.161|    51.5|   -0.122|         null|\n|May 14, 2024 @ 05...|      P0f|           GB|    49691|            null|United Kingdom| 87.236.176.161|    51.5|   -0.122|         null|\n|May 14, 2024 @ 05...|      P0f|           GB|    49691|            null|United Kingdom| 87.236.176.161|    51.5|   -0.122|         null|\n|May 14, 2024 @ 05...|      P0f|           US|     9020|North Charleston| United States|162.216.149.223|  32.875|      -80|         null|\n|May 14, 2024 @ 05...|      P0f|           US|     9020|North Charleston| United States|162.216.149.223|  32.875|      -80|         null|\n+--------------------+---------+-------------+---------+----------------+--------------+---------------+--------+---------+-------------+\nonly showing top 10 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "data_frame.where((col('country_code2').isNotNull()) & (col('country_code3').isNotNull())).count()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 31,
			"outputs": [
				{
					"name": "stdout",
					"text": "0\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#attempt at combining country_code columns\nfrom pyspark.sql.functions import udf\n\ndef combine(col_one, col_two):\n    if col_one is None and col_two is None:\n        return None\n    elif col_one is not None:\n        return col_one\n    else:\n        return col_two\n    \ncombine_udf = udf(combine)\n\ncolumns = [c for c in data_frame.schema.names] + [combine_udf(col(\"country_code2\"), col(\"country_code3\")).alias(\"country_code_combined\")]",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 32,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "data_frame = data_frame.select(*columns)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 33,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "data_frame.show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 34,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+---------+-------------+---------+---------+--------------+-------------+--------+---------+-------------+---------------------+\n|          @timestamp|     type|country_code2|dest_port|city_name|  country_name|           ip|latitude|longitude|country_code3|country_code_combined|\n+--------------------+---------+-------------+---------+---------+--------------+-------------+--------+---------+-------------+---------------------+\n|May 9, 2024 @ 12:...|      P0f|         null|    28015|     null| United States|199.45.155.25|   37.75|  -97.812|           US|                   US|\n|May 9, 2024 @ 12:...|      P0f|         null|    28015|     null| United States|199.45.155.25|   37.75|  -97.812|           US|                   US|\n|May 9, 2024 @ 12:...|      P0f|         null|    28015|     null| United States|199.45.155.25|   37.75|  -97.812|           US|                   US|\n|May 9, 2024 @ 12:...|      P0f|         null|    28015|     null| United States|199.45.155.25|   37.75|  -97.812|           US|                   US|\n|May 9, 2024 @ 12:...|      P0f|         null|    28015|     null| United States|199.45.155.25|   37.75|  -97.812|           US|                   US|\n|May 9, 2024 @ 12:...|      P0f|         null|    28015|     null| United States|199.45.155.25|   37.75|  -97.812|           US|                   US|\n|May 9, 2024 @ 12:...|Honeytrap|         null|    28015|     null| United States|199.45.155.25|   37.75|  -97.812|           US|                   US|\n|May 9, 2024 @ 11:...| Suricata|         null|      443|     null|          null|         null|    null|     null|         null|                 null|\n|May 9, 2024 @ 11:...| Suricata|         null|      443|     null|          null|         null|    null|     null|         null|                 null|\n|May 9, 2024 @ 11:...| Suricata|         null|      443|     null|          null|         null|    null|     null|         null|                 null|\n|May 9, 2024 @ 11:...| Suricata|         null|      443|     null|          null|         null|    null|     null|         null|                 null|\n|May 9, 2024 @ 11:...| Suricata|         null|      547|     null|          null|         null|    null|     null|         null|                 null|\n|May 9, 2024 @ 11:...| Suricata|         null|    10250|   London|United Kingdom|   3.9.144.57|    51.5|   -0.093|           GB|                   GB|\n|May 9, 2024 @ 11:...| Suricata|         null|      443|     null|          null|         null|    null|     null|         null|                 null|\n|May 9, 2024 @ 11:...| Suricata|         null|      443|     null|          null|         null|    null|     null|         null|                 null|\n|May 9, 2024 @ 11:...| Suricata|         null|    48946|     null|          null|         null|    null|     null|         null|                 null|\n|May 9, 2024 @ 11:...| Suricata|         null|    10250|   London|United Kingdom|   3.9.144.57|    51.5|   -0.093|           GB|                   GB|\n|May 9, 2024 @ 11:...| Suricata|         null|    10250|   London|United Kingdom|   3.9.144.57|    51.5|   -0.093|           GB|                   GB|\n|May 9, 2024 @ 11:...| Suricata|         null|      443|     null|          null|         null|    null|     null|         null|                 null|\n|May 9, 2024 @ 11:...| Suricata|         null|      443|     null|          null|         null|    null|     null|         null|                 null|\n+--------------------+---------+-------------+---------+---------+--------------+-------------+--------+---------+-------------+---------------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "data_frame.where(col('country_code_combined').isNull()).count()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 35,
			"outputs": [
				{
					"name": "stdout",
					"text": "1402550\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "Notice that the number of nulls above here is basically the same as the number of nulls in the country name column. Lets make sure these are all the same in order to prove the redundancy of the country code column.",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "data_frame.where((col('country_name').isNotNull()) & (col('country_code_combined').isNull())).count()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 36,
			"outputs": [
				{
					"name": "stdout",
					"text": "0\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "data_frame.where((col('country_name').isNull()) & (col('country_code_combined').isNotNull())).count()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 38,
			"outputs": [
				{
					"name": "stdout",
					"text": "0\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "The zeros above prove the redundancy in the country code columns, we can simply just keep the country name column due to the fact that if we have the country name column then that means that we have the country code. Therefore we can just keep the country name column. ",
			"metadata": {}
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Write the data in the DynamicFrame to a location in Amazon S3 and a table for it in the AWS Glue Data Catalog\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "# s3output = glueContext.getSink(\n#   path=\"s3://bucket_name/folder_name\",\n#   connection_type=\"s3\",\n#   updateBehavior=\"UPDATE_IN_DATABASE\",\n#   partitionKeys=[],\n#   compression=\"snappy\",\n#   enableUpdateCatalog=True,\n#   transformation_ctx=\"s3output\",\n# )\n# s3output.setCatalogInfo(\n#   catalogDatabase=\"demo\", catalogTableName=\"populations\"\n# )\n# s3output.setFormat(\"glueparquet\")\n# s3output.writeFrame(DyF)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 10,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}